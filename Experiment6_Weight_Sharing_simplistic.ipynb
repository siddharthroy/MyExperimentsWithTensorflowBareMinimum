{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Weight duplicating at Scale (Using loop)\n",
    "Same set of weights (i.e. CNN kernal or filter) to be used by every stride. Here we understand how to reuse the same set of weights as amny times as we like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create set of common weights (a CNN filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_weights = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "initial_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'cnn_filter1:0' shape=(3, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_filter1 = tf.Variable(initial_weights, dtype=tf.float32, name=\"cnn_filter1\")\n",
    "cnn_filter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cnn_filter1:0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_filter1.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup input image that needs to be <font color=\"red\"> morphed </font> into target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.,  20.,  30.,  40.,  50.,  60.],\n",
       "       [ 70.,  80.,  90., 100., 110., 120.],\n",
       "       [130., 140., 150., 160., 170., 180.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_image=np.array([[10,20,30,40,50,60],[70,80,90,100,110,120],[130,140,150,160,170,180.]])\n",
    "ip_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 22.,  44.,  62.,  81., 103., 122.],\n",
       "       [143., 161., 181., 200., 221., 241.],\n",
       "       [260., 280., 301., 323., 344., 360.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "target_image = 2*ip_image + np.random.randint(0,5, size=[3,6])\n",
    "target_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder to hold your input & target image images into DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_tensor1 = tf.placeholder(dtype=tf.float32, name=\"im_tensor1\")\n",
    "im_tensor2 = tf.placeholder(dtype=tf.float32, name=\"im_tensor2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Share the weights or filter1 among patches of image\n",
    "Simply using python variables (No big deal) <br>\n",
    "- <font color=\"red\">Important to note: ***Don't confuse operation node as \"variable\"***</font><br>\n",
    "\n",
    ">**DAG becomes very bulky as number of patches increases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DAG on just one slice.\n",
    "# During training, iteratively use sliding slices\n",
    "\n",
    "losses_list = []\n",
    "s = 1                # Stride step size\n",
    "tot_patches = int( (ip_image.shape[1] - initial_weights.shape[1])/s + 1 )\n",
    "\n",
    "for p_idx in range(tot_patches):\n",
    "    patch = im_tensor1[:, s*p_idx:s*(p_idx+1)]     # Slicing operation\n",
    "    a_map = patch*cnn_filter1                      # Element wise multiplication op on that slice\n",
    "    \n",
    "    loss = tf.square(im_tensor2[:, s*p_idx:s*(p_idx+1)] - a_map)\n",
    "    losses_list.append(tf.sqrt(tf.reduce_sum(loss)))    # List of all loss ops. Becomes Tensorflow op named \"Pack\" (shows as Rank_4 in tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Sqrt:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Sqrt_1:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Sqrt_2:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Sqrt_3:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost op\n",
    "cost = tf.reduce_sum(losses_list, name=\"cost\")   # List (even of operations) can be reduce_sum'ed to create new op, namely \"cost\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "set_to_optimize = optimize.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go ahead and execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph writer first\n",
    "writer = tf.summary.FileWriter(logdir=\"./Graph\", graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just one pass of optimization at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6346.377"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check starting cost\n",
    "sess.run(cost, feed_dict={im_tensor1:ip_image, im_tensor2:target_image})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166.91614"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train 100 times\n",
    "for i in range(100):\n",
    "    sess.run(set_to_optimize, feed_dict={im_tensor1:ip_image, im_tensor2:target_image})\n",
    "\n",
    "sess.run(cost, feed_dict={im_tensor1:ip_image, im_tensor2:target_image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0700092, 2.0700092, 2.0700092],\n",
       "       [2.0141253, 2.0141253, 2.0141253],\n",
       "       [2.013653 , 2.1378007, 2.2616987]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After finishing optimization (multiple runs of above cell), check CNN-Filter\n",
    "sess.run(cnn_filter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember the start weights?\n",
    "initial_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion:\n",
    "# All weights came close to 2. This is expected, as morphed image is just twice of original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
